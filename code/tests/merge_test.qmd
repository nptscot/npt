```{r}
remotes::install_dev("stplanr")
packageVersion("stplanr")
sf::sf_use_s2(TRUE)
library(stplanr)
library(dplyr)
library(sf)
library(mapview)
library(tmap)
library(tidyr)
```
The code below is used to generate OS_large_route_network_example_edingurgh.geojson.
- read all the shapefiles in the folder
- filter out the unclassified roads
- combine all the shapefiles
- reproject the combined data to EPSG:4326
- save the reprojected data as a GeoJSON
- clip the larger GeoJSON using the buffer

OS Open Roads download link: https://osdatahub.os.uk/downloads/open/OpenRoads?_gl=1*1lsqtad*_ga*MTgxNDYyMTAwNy4xNjk3MTQzNjQy*_ga_59ZBN7DVBG*MTY5NzE0MzY0Mi4xLjEuMTY5NzE0MzY1MS41MS4wLjA.&_ga=2.126966605.1537450082.1697143643-1814621007.1697143642

```{python,eval = FALSE}
import geopandas as gpd
import os
import pandas as pd

# Define the path
path = "V:/data/"

# List all SHP files in the path that contain "_RoadLink" in their filename
all_files = [os.path.join(path, file) for file in os.listdir(path) if file.endswith('.shp') and "_RoadLink" in file]

# Read, filter, and combine all the shapefiles
filtered_gdfs = []
for file in all_files:
    gdf = gpd.read_file(file)
    
    # Ensure the current CRS is set to EPSG:27700
    gdf.set_crs(epsg=27700, inplace=True)
    
    # Filter the GeoDataFrame and append to list
    filtered_gdf = gdf[
        (gdf['class'] != 'Unknown') & 
        (
            ~gdf['function'].isin(['Secondary Access Road', 'Restricted Local Access Road']) | 
            (gdf['function'].isin(['Secondary Access Road', 'Restricted Local Access Road']) & 
            gdf['formOfWay'].str.contains('Dual', case=False))
        )
    ]
    filtered_gdfs.append(filtered_gdf)

# Concatenate all the filtered GeoDataFrames
combined_gdf = gpd.GeoDataFrame(pd.concat(filtered_gdfs, ignore_index=True))

# Reproject the combined data to EPSG:4326
combined_gdf = combined_gdf.to_crs(epsg=4326)

# Save the reprojected data as a GeoJSON
output_path = os.path.join(path, "OS_UK.geojson")
combined_gdf[['identifier', 'geometry']].to_file(output_path, driver="GeoJSON")
print(f"Filtered and reprojected GeoJSON saved to: {output_path}")
```

The code provided below is used to merge the NPT network with the OS network.

```{r}
# Read spatial data directly from URLs into sf objects
rnet_x = sf::read_sf("https://github.com/nptscot/networkmerge/releases/download/v0.1/OS_large_route_network_example_edingurgh.geojson")
rnet_y = sf::read_sf("https://github.com/nptscot/networkmerge/releases/download/v0.1/combined_network_tile.geojson")

# rnet_x = sf::read_sf("https://github.com/ropensci/stplanr/releases/download/v1.0.2/rnet_x_ed.geojson")
# rnet_y = sf::read_sf("https://github.com/ropensci/stplanr/releases/download/v1.0.2/rnet_y_ed.geojson")

rnet_xp = rnet_x
rnet_yp = rnet_y
# Transform the spatial data to a different coordinate reference system (EPSG:27700)
# rnet_xp = st_transform(rnet_x, "EPSG:27700")
# rnet_yp = st_transform(rnet_y, "EPSG:27700")

# Extract column names from the rnet_xp data frame
name_list = names(rnet_yp)

# Initialize an empty list
funs = list()

# Loop through each name and assign it a function based on specific conditions
for (name in name_list) {
  if (name == "geometry") {
    next  # Skip the current iteration
  } else if (name %in% c("Gradient", "Quietness")) {
    funs[[name]] = mean
  } else {
    funs[[name]] = sum
  }
}


# Define breaks for categorizing data
brks = c(0, 50, 100, 200, 500,1000, 2000, 5000,10000,150000)

# Merge the spatial objects rnet_xp and rnet_yp based on specified parameters
dist = 20
angle = 10

rnet_merged_all = rnet_merge(rnet_xp, rnet_yp, dist = dist, segment_length = 10, funs = funs, max_angle_diff = angle) 

# names(rnet_merged_all)
# Remove specific columns from the merged spatial object
rnet_merged_all = rnet_merged_all[ , !(names(rnet_merged_all) %in% c('identifier','length_x'))]

# Remove Z and M dimensions (if they exist) and set geometry precision
rnet_merged_all = st_zm(rnet_merged_all, what = "ZM")
rnet_merged_all$geometry = st_set_precision(rnet_merged_all$geometry, 1e3)
rnet_merged_all = rnet_merged_all %>%
  mutate(across(where(is.numeric), ~ round(.x, 0)))      

# Define columns to check for NA values
rnet_yp_list = as.list(names(rnet_yp))

# Remove the "geometry" entry from the list
columns_to_check = unlist(rnet_yp_list[rnet_yp_list != "geometry"])

# Remove rows where all specified columns are NA using dplyr's select and filter functions
rnet_merged_all <- rnet_merged_all %>%
  filter(rowSums(is.na(select(., all_of(columns_to_check)))) != length(columns_to_check))
  
timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
timestamp
# Write the spatial object to a GeoJSON file 
st_write(rnet_merged_all, paste0("data-raw/rnet_merged_all_", dist, "_", angle,"_", timestamp, ".geojson"), driver = "GeoJSON")

```
The R code below is used to identify the roads missed during the merge process and then integrate them into the simplified network.

! the st_join is running  extremely slow, need to find a way to speed it up. 
Current solution using python to solve in next chunk


```{r}
dist = 20
angle = 10
timestamp = "20231019_162607"

# rnet_merged_all <- st_read(paste0("data-raw/rnet_merged_all_", dist, "_", angle, "_", timestamp, ".geojson"))
rnet_merged_all <- st_read("G:/Github/tmp/npt/tmp/rnet_merged_all.gpkg")
names(rnet_y)
rnet_y <- st_read("G:/combined_network_tile.geojson")
# rnet_y = sf::read_sf("https://github.com/ropensci/stplanr/releases/download/v1.0.2/rnet_y_ed.geojson")
# rnet_yp <- st_transform(rnet_y, 27700)
rnet_yp = rnet_y
# Buffering
rnet_merged_all_buffer <- st_buffer(rnet_merged_all, dist = dist, endCapStyle = "FLAT")

# Unary Union and conversion to GeoDataFrame
single_rnet_merged_all_buffer <- st_union(rnet_merged_all_buffer)
single_rnet_merged_all_buffer_gdf <- st_sf(geometry = single_rnet_merged_all_buffer)

rnet_yp <- st_make_valid(rnet_yp)

single_rnet_merged_all_buffer_gdf <- st_make_valid(single_rnet_merged_all_buffer_gdf)

# Spatial Join
within_join <- st_join(rnet_yp, single_rnet_merged_all_buffer_gdf, join = st_within)

# Filtering geometries not within the buffer
rnet_yp_rest <- rnet_yp[!rnet_yp$geometry %in% within_join$geometry, ]

rnet_merged_all <- rnet_merged_all %>%
  rename(geometry = geom)
names(rnet_merged_all)
# Concatenation (vertical stacking)
combined_data <- bind_rows(rnet_yp_rest, rnet_merged_all)
# Compare the structure of the two data frames
str(rnet_yp_rest)
str(rnet_merged_all)

# Set CRS
combined_data <- st_transform(combined_data, 4326)

# Define columns to check for NA values
list = names(combined_data)

items_to_remove = c('geometry', 'length_x_original', 'length_x_cropped')
# Remove the "geometry" entry from the list
cols_to_convert = unlist(list[!(list %in% items_to_remove)])

# Handling NA and conversion to integer
combined_data[cols_to_convert] <- replace_na(combined_data[cols_to_convert], list(0))

combined_data[cols_to_convert] <- lapply(combined_data[cols_to_convert], function(x) {
  x <- replace_na(x, 0)
  round(x, 0)
})
str(combined_data[cols_to_convert])
# Saving to GeoJSON
st_write(combined_data, paste0("data-raw/simplified_network_npt_", dist, "_", angle, "_", timestamp, ".geojson"))
```

The python code below is used to identify the roads missed during the merge process and then integrate them into the simplified network.


```{python}
import geopandas as gpd
from shapely.geometry import MultiPolygon
import pandas as pd
import os

# Get the current working directory
current_working_directory = os.getcwd()
relative_path = "tmp/rnet_merged_all.gpkg"

# Construct the full path to the file
full_file_path = os.path.join(current_working_directory, relative_path)

# rnet_merged_all = gpd.read_file(f"data-raw/rnet_merged_all_{dist}_{angle}_{timestamp}.geojson")
rnet_merged_all = gpd.read_file(full_file_path)

rnet_y = gpd.read_file("G:/npt-2/data-raw/combined_network_tile.geojson")
# rnet_y = gpd.read_file("https://github.com/ropensci/stplanr/releases/download/v1.0.2/rnet_y_ed.geojson")

rnet_yp = rnet_y

# Set buffer distance and create a buffered GeoDataFrame around rnet_merged_all geometries, using a flat end cap style

rnet_merged_all_buffer = rnet_merged_all.buffer(0.0002, cap_style=3)

# Create a unary union of the buffered geometries to create a single geometry object
single_rnet_merged_all_buffer = rnet_merged_all_buffer.unary_union
# Convert the single geometry object into a GeoDataFrame
single_rnet_merged_all_buffer_gdf = gpd.GeoDataFrame(geometry=[single_rnet_merged_all_buffer])

# Perform a spatial join between rnet_yp and the buffer, keeping only those geometries from rnet_yp that are within the buffer
within_join = gpd.sjoin(rnet_yp, single_rnet_merged_all_buffer_gdf, op='within')

# Keep only those geometries from rnet_yp that were NOT within the buffer
rnet_yp_rest = rnet_yp.loc[~rnet_yp.index.isin(within_join.index)]

# Concatenate (vertically stack) the rnet_yp_rest and rnet_merged_all GeoDataFrames and check the number of columns
combined_data = gpd.GeoDataFrame(pd.concat([rnet_yp_rest, rnet_merged_all], ignore_index=True))

combined_data = combined_data.to_crs(epsg=4326)

cols_to_convert = combined_data.columns.to_list()

items_to_remove = ['geometry', 'length_x_original', 'length_x_cropped', 'value']

# Remove items from the list
cols_to_convert = [col for col in cols_to_convert if col not in items_to_remove]

combined_data[cols_to_convert] = combined_data[cols_to_convert].fillna(0)

combined_data[cols_to_convert] = combined_data[cols_to_convert].round().astype(int)

combined_data.to_file(r"G:\Github\npt\data-raw\simplified_network_npt.geojson", driver='GeoJSON')

```


```{r}
library(targets)
setwd("~/../github/nptscot/npt")
tar_load(simplify_network)

```